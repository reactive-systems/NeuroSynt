{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "\n",
    "We first do some imports and then load the different evaluations of the neural solver and symbolic tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurosynt import NeuroSyntEvalDataset\n",
    "from ml2.dtypes import CSVDict\n",
    "from ml2.ltl.ltl_syn import LTLSynEvalDataset\n",
    "from ml2.globals import LOCAL_STORAGE_DIR\n",
    "from copy import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SYNTCOMP 2022\n",
    "\n",
    "Load the SYNTCOMP 2022 evaluation data from the starexec platform and convert it into a EvalDataset\n",
    "\n",
    "Unfortunateley this takes quite some time (~4min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntcomp_data: NeuroSyntEvalDataset = NeuroSyntEvalDataset.from_syntcomp(\n",
    "    dtype=CSVDict, name=\"Syntcomp\", filename=LOCAL_STORAGE_DIR + \"/ltl-syn/syntcomp2022.zip\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load neurosynt evaluations\n",
    "\n",
    "The following loads previous evaluations.\n",
    "\n",
    "If one has performed own full evaluations, replace all `neurosynt-benchmarking-...` with the new evaluations (for example `neurosynt-bm-full-strix`) to fully reproduce all results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuroSynt_Strix on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_s: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-6\")  # type: ignore\n",
    "benchmark_s.df[\"result_tool\"] = benchmark_s.df.apply(\n",
    "    lambda row: \"NeuroSynt-S\" if row[\"result_tool\"] == \"NeuroSynt\" else row[\"result_tool\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuroSynt_BoSy on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_b: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-7\")  # type: ignore\n",
    "benchmark_b.df[\"result_tool\"] = benchmark_b.df.apply(\n",
    "    lambda row: \"NeuroSynt-B\" if row[\"result_tool\"] == \"NeuroSynt\" else row[\"result_tool\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuroSynt_Strix on GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_g: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-8\")  # type: ignore\n",
    "benchmark_g.df[\"result_tool\"] = benchmark_g.df.apply(lambda row: row[\"result_tool\"] + \"-G\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuroSynt_Strix on CPU cluster (Timeout 1h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_l: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-9\")  # type: ignore\n",
    "benchmark_l.df[\"result_tool\"] = benchmark_l.df.apply(\n",
    "    lambda row: row[\"result_tool\"] + \"-L\", axis=1\n",
    ")  # Strix timeout 3600s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeuroSynt_Strix on MPB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_local: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-10\")  # type: ignore\n",
    "benchmark_local.df[\"result_tool\"] = benchmark_local.df.apply(\n",
    "    lambda row: row[\"result_tool\"] + \"-Local\", axis=1\n",
    ")  # Strix timeout 3600s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load second and third neural solver model (alternative model/ configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_120: NeuroSyntEvalDataset = NeuroSyntEvalDataset.load(\"ltl-syn/neurosynt-benchmarking-0\")\n",
    "benchmark_120.df[\"result_tool\"] = benchmark_120.df.apply(\n",
    "    lambda row: row[\"result_tool\"] + \"-120\", axis=1\n",
    ")\n",
    "\n",
    "evaluation45 = NeuroSyntEvalDataset.from_LTLSynEvalDataset(\n",
    "    LTLSynEvalDataset.load(\"ltl-syn/ht-45-eval-0/eval/0/1/csv_logger\"), name=\"ht45eval\"\n",
    ")\n",
    "evaluation45.df[\"result_tool\"] = evaluation45.df.apply(\n",
    "    lambda row: row[\"result_tool\"] + \"-45\", axis=1\n",
    ")\n",
    "\n",
    "evaluation45 = NeuroSyntEvalDataset(\n",
    "    df=evaluation45.smallest_samples(include_invalid=True),\n",
    "    add_stats=False,\n",
    "    dtype=CSVDict,\n",
    "    name=\"ht45eval\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple evaluation into one evaluation.\n",
    "\n",
    "for easier calculations of the virtual best solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = NeuroSyntEvalDataset.from_merge(\n",
    "    [\n",
    "        benchmark_s,\n",
    "        benchmark_b,\n",
    "        benchmark_g,\n",
    "        benchmark_l,\n",
    "        benchmark_local,\n",
    "        syntcomp_data,\n",
    "    ],\n",
    "    name=\"merged\",\n",
    "    project=\"ltl-syn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Solves (Table 2)\n",
    "\n",
    "in the following we describe, how the columns of Table 2 can be reproduced.\n",
    "\n",
    "First, we create a virtual best solver for all configurations of each tool. This refelcts the _grouped configurations_ columns.\n",
    "Then, the three columns follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_neurosynt = NeuroSyntEvalDataset.from_merge(\n",
    "    [\n",
    "        benchmark_s,\n",
    "        benchmark_120,\n",
    "        evaluation45,\n",
    "        benchmark_b,\n",
    "        benchmark_g,\n",
    "        benchmark_l,\n",
    "    ],\n",
    "    name=\"merged\",\n",
    "    project=\"ltl-syn\",\n",
    ")\n",
    "\n",
    "collapsed_neurosynt = merged_neurosynt.collapse(\n",
    "    collapse_dict={\n",
    "        \"NeuroSynt\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"NeuroSynt\"),\n",
    "                list(merged_neurosynt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "    },\n",
    "    smallest=True,\n",
    "    fastest=False,\n",
    ")\n",
    "collapsed_neurosynt.df = collapsed_neurosynt.df[\n",
    "    collapsed_neurosynt.df[\"result_tool\"] == \"NeuroSynt\"\n",
    "]\n",
    "\n",
    "merged_symbolic = NeuroSyntEvalDataset.from_merge(\n",
    "    [\n",
    "        benchmark_s,\n",
    "        benchmark_b,\n",
    "        benchmark_g,\n",
    "        benchmark_l,\n",
    "        syntcomp_data,\n",
    "    ],\n",
    "    name=\"merged\",\n",
    "    project=\"ltl-syn\",\n",
    ")\n",
    "\n",
    "collapsed_symbolic = merged_symbolic.collapse(\n",
    "    collapse_dict={\n",
    "        \"Strix\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"Strix\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"BoSy\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"BoSy\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"Otus\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"Otus\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"ltlsynt\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"ltlsynt\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"sdf\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"sdf\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"NeuroSynt\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"NeuroSynt\"),\n",
    "                list(merged_symbolic.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "    },\n",
    "    fastest=True,\n",
    ")\n",
    "\n",
    "collapsed_symbolic.df = collapsed_symbolic.df[collapsed_symbolic.df[\"result_tool\"] != \"NeuroSynt\"]\n",
    "\n",
    "collapsed = NeuroSyntEvalDataset.from_merge(\n",
    "    [\n",
    "        collapsed_neurosynt,\n",
    "        collapsed_symbolic,\n",
    "    ],\n",
    "    name=\"collapsed\",\n",
    "    project=\"ltl-syn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first column: total solved, best configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {\n",
    "    \"Strix\": (0, \"\"),\n",
    "    \"NeuroSynt\": (0, \"\"),\n",
    "    \"sdf\": (0, \"\"),\n",
    "    \"ltlsynt\": (0, \"\"),\n",
    "    \"BoSy\": (0, \"\"),\n",
    "    \"Otus\": (0, \"\"),\n",
    "}\n",
    "\n",
    "for tool in list(merged.df[\"result_tool\"].value_counts().index):\n",
    "    solved = len(merged.solved_by([tool]))\n",
    "    # print(tool)\n",
    "    # print(solved)\n",
    "    for el in best:\n",
    "        if tool.startswith(el):\n",
    "            if best[el][0] < solved:\n",
    "                best[el] = solved, tool\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second column, grouped configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in list(collapsed.df[\"result_tool\"].value_counts().index):\n",
    "    solved = len(collapsed.solved_by([tool]))\n",
    "    print(tool)\n",
    "    print(solved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "third column: exclusively solved grouped configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in best:\n",
    "    print(el)\n",
    "    print(\n",
    "        len(\n",
    "            collapsed.exclusively_solved(\n",
    "                by_tool=el,\n",
    "                out_of_tools=list(collapsed.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cactus Plot (Fig 8)\n",
    "\n",
    "This is the cactus plot from Fig. 8\n",
    "\n",
    "The first cell is how to create the plot, the second cell is the creation of the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def sort_column(df: pd.DataFrame, column):\n",
    "    df = df.reset_index()\n",
    "    return df.sort_values(by=column).reset_index().drop(\"index\", axis=1).reset_index()\n",
    "\n",
    "\n",
    "def cactus_plot(dfs: Dict[str, Tuple[pd.DataFrame, Dict]], column=\"result_duration_par\", log=True):\n",
    "    def cactus(df: pd.DataFrame, name: str, line_format: Dict):\n",
    "        df = sort_column(df, column)\n",
    "\n",
    "        def column_sum(row):\n",
    "            return df[: row[\"index\"] + 1][column].sum()\n",
    "\n",
    "        df[\"column_sum\"] = df.apply(column_sum, axis=1)\n",
    "\n",
    "        return go.Scatter(\n",
    "            x=df[\"index\"], y=df[\"column_sum\"], name=name, mode=\"lines\", line=line_format\n",
    "        )\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for k, (df, line_format) in dfs.items():\n",
    "        fig.add_trace(cactus(df, k, line_format))\n",
    "    if log:\n",
    "        fig.update_yaxes(type=\"log\", exponentformat=\"power\", dtick=\"D3\")\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"total wall-clock time (s)\",\n",
    "        gridcolor=\"#e8e8e8\",\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        title_text=\" No. of solved benchmarks (Total: 1075)\",\n",
    "        tickmode=\"array\",\n",
    "        tickvals=[x * 25 for x in range(0, 44)],\n",
    "        ticktext=[str(x * 25) if x % 2 == 0 else \"\" for x in range(0, 44)],\n",
    "        range=[0, 1080],\n",
    "        gridcolor=\"#e8e8e8\",\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        font=dict(color=\"black\"),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.05,\n",
    "            xanchor=\"right\",\n",
    "            x=0.99,\n",
    "            font=dict(\n",
    "                size=13,\n",
    "            ),\n",
    "        ),\n",
    "        height=400,\n",
    "        width=900,\n",
    "        margin=dict(l=0, r=10, t=10, b=0),\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    fig.show(config={\"staticPlot\": True})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cactus_plot(\n",
    "    {\n",
    "        \"Neural Solver\": (\n",
    "            merged.fastest_samples(out_of_tools=[\"NeuroSynt-G\"]),\n",
    "            dict(color=\"black\"),\n",
    "        ),\n",
    "        \"BoSy\": (\n",
    "            merged.fastest_samples(out_of_tools=[\"BoSy\"]),\n",
    "            dict(color=\"#009cc4\", dash=\"dash\"),\n",
    "        ),\n",
    "        \"NeuroSynt<sub>BoSy\": (\n",
    "            merged.fastest_samples(out_of_tools=[\"NeuroSynt-G\", \"BoSy\"]),\n",
    "            dict(color=\"#009cc4\"),\n",
    "        ),\n",
    "        \"Strix\": (\n",
    "            merged.fastest_samples(out_of_tools=[\"Strix-L\"]),\n",
    "            dict(color=\"#ff7f23\", dash=\"dash\"),\n",
    "        ),\n",
    "        \"NeuroSynt<sub>Strix\": (\n",
    "            merged.fastest_samples(out_of_tools=[\"NeuroSynt-G\", \"Strix-L\"]),\n",
    "            dict(color=\"#ff7f23\"),\n",
    "        ),\n",
    "        \"Virtual Best Solver<br><span style='font-size: 11px;'>(symbolic)</span>\": (\n",
    "            merged.fastest_samples(\n",
    "                out_of_tools=list(\n",
    "                    filter(\n",
    "                        lambda x: not x.startswith(\"NeuroSynt\"),\n",
    "                        list(merged.df[\"result_tool\"].value_counts().index),\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "            dict(color=\"#008040\", dash=\"dash\"),\n",
    "        ),\n",
    "        \"Virtual Best Solver<br><span style='font-size: 11px;'>(symbolic & neural)</span>\": (\n",
    "            merged.fastest_samples(),\n",
    "            dict(color=\"#008040\"),\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Solves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the names of the novel solves that we report in the paper.\n",
    "\n",
    "These names correlate to the official files from SYNTCOMP 2022.\n",
    "A copy can be found in `~/ml2-storage/ltl-spec/sc-1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed.exclusively_solved(by_tool=\"NeuroSynt\")[\"input_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Times (Table 3)\n",
    "\n",
    "Here we reproduce the times from Table 3.\n",
    "\n",
    "For each tool we list different hardware, mean and standard deviation.\n",
    "\n",
    "For the neural solver, we additionally report the time for model checking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural solver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of neural solver (including model checking) on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(benchmark_b.solved_by([\"NeuroSynt-B\"])[\"result_duration_par\"].mean())\n",
    "print(benchmark_b.solved_by([\"NeuroSynt-B\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of model checking for the neural solver on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"NeuroSynt-B\"])[\"result_model_checking_duration\"].astype(float).mean())\n",
    "print(merged.solved_by([\"NeuroSynt-B\"])[\"result_model_checking_duration\"].astype(float).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of neural solver (including model checking) on MBP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"NeuroSynt-Local\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"NeuroSynt-Local\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of model checking for the neural solver on MPB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"NeuroSynt-Local\"])[\"result_model_checking_duration\"].astype(float).mean())\n",
    "print(merged.solved_by([\"NeuroSynt-Local\"])[\"result_model_checking_duration\"].astype(float).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of neural solver (including model checking) on GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"NeuroSynt-G\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"NeuroSynt-G\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration of model checking for the neural solver on GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"NeuroSynt-G\"])[\"result_model_checking_duration\"].astype(float).mean())\n",
    "print(merged.solved_by([\"NeuroSynt-G\"])[\"result_model_checking_duration\"].astype(float).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Solver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strix on GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"Strix-G\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"Strix-G\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strix on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"Strix\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"Strix\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strix 1h timeout (CPU cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"Strix-L\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"Strix-L\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strix best SYNTCOMP config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"Strix-ltl_synth_zlk_bfs\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"Strix-ltl_synth_zlk_bfs\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bosy on CPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.solved_by([\"BoSy\"])[\"result_duration_par\"].mean())\n",
    "print(merged.solved_by([\"BoSy\"])[\"result_duration_par\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sizes (Table 4, Fig 9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4\n",
    "\n",
    "here we describe how to reproduce the results from Table 4 line by line. We follow the same order as in the paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strix and BoSy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = merged.compare_smaller(by_tool=\"NeuroSynt-G\", out_of_tools=[\"NeuroSynt-G\", \"Strix-L\"])\n",
    "print(\"On samples that Strix and the neural solver solved\")\n",
    "print(\"average Strix:\", r[\"out_of_tools but not by_tools average\"])\n",
    "print(\"average  neural solver:\", r[\"by_tool average\"])\n",
    "print(\n",
    "    \"neural solver smaller by\",\n",
    "    r[\"% smaller or larger than out_of_tools but not by_tools average\"],\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = merged.compare_smaller(by_tool=\"NeuroSynt-G\", out_of_tools=[\"NeuroSynt-G\", \"BoSy\"])\n",
    "print(\"On samples that BoSy and the neural solver solved\")\n",
    "print(\"average BoSy:\", r[\"out_of_tools but not by_tools average\"])\n",
    "print(\"average  neural solver:\", r[\"by_tool average\"])\n",
    "print(\n",
    "    \"neural solver smaller by\",\n",
    "    r[\"% smaller or larger than out_of_tools but not by_tools average\"],\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On realizable Syntcomp\n",
    "\n",
    "We first merge our own evaluations of the neural solver with the SYNTCOMP 2022 results. For each tool, we create a virtual best solver that comprises all configurations of one tool. The virtual best criteria is circuit size. As the SYNTCOMP only reports systems for realizable specifications, we only consider realizable specifications in this context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_alt = NeuroSyntEvalDataset.from_merge(\n",
    "    [\n",
    "        benchmark_s,\n",
    "        benchmark_120,\n",
    "        evaluation45,\n",
    "        benchmark_b,\n",
    "        benchmark_g,\n",
    "        benchmark_l,\n",
    "        syntcomp_data,\n",
    "    ],\n",
    "    name=\"merged\",\n",
    "    project=\"ltl-syn\",\n",
    ")\n",
    "\n",
    "collapsed_smallest = merged_alt.collapse(\n",
    "    collapse_dict={\n",
    "        \"Strix\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"Strix\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"BoSy\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"BoSy\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"Otus\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"Otus\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"ltlsynt\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"ltlsynt\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"sdf\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"sdf\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "        \"NeuroSynt\": list(\n",
    "            filter(\n",
    "                lambda x: x.startswith(\"NeuroSynt\"),\n",
    "                list(merged_alt.df[\"result_tool\"].value_counts().index),\n",
    "            )\n",
    "        ),\n",
    "    },\n",
    "    smallest=True,\n",
    "    fastest=False,\n",
    "    realizable_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately we found a bug that led to wrong calculation of the intersections of samples (i.e. commonly solved) between the tools from SYNTCOMP and our neural solver.\n",
    "\n",
    "This is in regard to the last three results of the Table 4 in the appendix. Following are the updated results.\n",
    "\n",
    "The trend and what is being reported in the main part of the paper (_The neural solver produces smaller solutions than any other solver in SYNTCOMP 2002_) still holds.\n",
    "\n",
    "We will correct that in the final version of the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = collapsed_smallest.compare_smaller(by_tool=\"NeuroSynt\", out_of_tools=[\"NeuroSynt\", \"ltlsynt\"])\n",
    "print(\"On samples that ltlsynt and the neural solver solved\")\n",
    "print(\"average ltlsynt:\", r[\"out_of_tools but not by_tools average\"])\n",
    "print(\"average  neural solver:\", r[\"by_tool average\"])\n",
    "print(\n",
    "    \"neural solver smaller by\",\n",
    "    r[\"% smaller or larger than out_of_tools but not by_tools average\"],\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_smallest.compare_smaller(by_tool=\"NeuroSynt\", out_of_tools=[\"NeuroSynt\", \"Otus\"])\n",
    "print(\"On samples that Otus and the neural solver solved\")\n",
    "print(\"average Otus:\", r[\"out_of_tools but not by_tools average\"])\n",
    "print(\"average  neural solver:\", r[\"by_tool average\"])\n",
    "print(\n",
    "    \"neural solver smaller by\",\n",
    "    r[\"% smaller or larger than out_of_tools but not by_tools average\"],\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_smallest.compare_smaller(by_tool=\"NeuroSynt\", out_of_tools=[\"NeuroSynt\", \"sdf\"])\n",
    "print(\"On samples that sdf and the neural solver solved\")\n",
    "print(\"average sdf:\", r[\"out_of_tools but not by_tools average\"])\n",
    "print(\"average  neural solver:\", r[\"by_tool average\"])\n",
    "print(\n",
    "    \"neural solver smaller by\",\n",
    "    r[\"% smaller or larger than out_of_tools but not by_tools average\"],\n",
    "    \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 9\n",
    "\n",
    "Herre we plot the size of circuits (no. of latches) for Strix and the neural solver on commonly solved samples.\n",
    "\n",
    "The first cell is how to create the plot, the second cell is the creation of the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def group_by(df, group_fn, column):\n",
    "    d = {\n",
    "        k: group_fn(group)\n",
    "        for k, group in [(k, df.loc[v]) for k, v in df.groupby(by=column).groups.items()]\n",
    "    }\n",
    "    return pd.DataFrame.from_dict(d, orient=\"index\").dropna()\n",
    "\n",
    "\n",
    "def min_max_scaling(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "\n",
    "def plot_hist(\n",
    "    df_1: Tuple[pd.DataFrame, str],\n",
    "    df_2: Tuple[pd.DataFrame, str],\n",
    "    column: str,\n",
    "    group_fn,\n",
    "):\n",
    "    dataframe_1 = group_by(df_1[0], group_fn, column).reset_index()\n",
    "    dataframe_2 = group_by(df_2[0], group_fn, column).reset_index()\n",
    "\n",
    "    data = []\n",
    "    data.append(\n",
    "        go.Bar(\n",
    "            name=df_1[1],\n",
    "            x=dataframe_1[\"index\"],\n",
    "            y=dataframe_1[0],\n",
    "            marker_color=\"#009cc4\",\n",
    "            # marker_color=\"black\",\n",
    "        )\n",
    "    )\n",
    "    data.append(\n",
    "        go.Bar(\n",
    "            name=df_2[1],\n",
    "            x=dataframe_2[\"index\"],\n",
    "            y=dataframe_2[0],\n",
    "            marker_color=\"#ff7f23\",\n",
    "            # marker_color=\"black\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"no. of instances\",\n",
    "        dtick=25,\n",
    "        gridcolor=\"#e8e8e8\",\n",
    "    )\n",
    "    fig.update_xaxes(title_text=column, dtick=1, tick0=0)\n",
    "    fig.update_layout(\n",
    "        font=dict(color=\"black\"),\n",
    "        barmode=\"group\",\n",
    "        # showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.95,\n",
    "            xanchor=\"right\",\n",
    "            x=0.99,\n",
    "            font=dict(size=13),\n",
    "        ),\n",
    "        colorscale={\"sequential\": px.colors.qualitative.G10},\n",
    "        height=300,\n",
    "        width=900,\n",
    "        margin=dict(l=0, r=10, t=10, b=0),\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy(merged.solved_by([\"NeuroSynt-G\", \"Strix-L\"]))\n",
    "\n",
    "df[\"latches\"] = df.apply(NeuroSyntEvalDataset.get_latches, axis=1)\n",
    "\n",
    "fig = plot_hist(\n",
    "    (df[df[\"result_tool\"] == \"NeuroSynt-G\"], \"Neural Solver\"),\n",
    "    (df[df[\"result_tool\"] == \"Strix-L\"], \"Strix\"),\n",
    "    \"latches\",\n",
    "    len,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
